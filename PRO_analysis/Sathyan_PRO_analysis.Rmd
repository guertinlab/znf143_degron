---
title: PRO-seq analysis
author:
- Jinhong Dong
- Michael J. Guertin 
header-includes:
- \usepackage{color}
- \usepackage{float}
- \DeclareUnicodeCharacter{2212}{-}
date: "`r Sys.Date()`"
output:
  bookdown::html_document2:
    toc: true
fontsize: 14pt
geometry: margin=1in
---

# Introduction

This is a vignette for PRO-seq analysis accompanying the manuscript "ZNF143 binds DNA and stimulates transcription initiation to activate and repress direct target genes" (doi: https://doi.org/10.1101/2024.05.13.594008). The analysis follows the published figures, which may differ from the preprint figures in labeling and content.

# PRO-seq analysis

Combine FASTQs for ZNF143-dTAG PRO-seq data from two different sequencing runs:
```{r engine='bash', eval=F, echo=TRUE}
cd /labs/Guertin/ZNF143_PRO

for i in ./dep1/*_dep1_*.fastq.gz
do
    echo $i
    pre=$(echo $i | awk -F"/" '{print $NF}' | awk -F"_dep1_" '{print $1}')
    suf=$(echo $i | awk -F"/" '{print $NF}' | awk -F"_dep1_" '{print $2}')
    x=$(echo $suf |  awk -F".fastq" '{print $1}')
    echo $pre # cell type, treatment, condition
    echo $suf # replicate number, PE2, fastq.gz
    echo $x # replicate number, PE2
    cat $i ./dep2/${pre}_dep2_${suf} > ${pre}_${x}_final.fastq.gz
done 
```

 Load modules, pre-run seqOutBias, and parse the hg38 annotation file:

```{r engine='bash', eval=F, echo=TRUE}
module load bowtie2/2.5.0
module load genometools/1.5.10
module load bedtools/2.29.0
module load ucsc_genome/2012.05.22
module load rust 

release=109

wget https://raw.githubusercontent.com/guertinlab/fqComplexity/main/fqComplexity
wget https://raw.githubusercontent.com/guertinlab/fqComplexity/main/complexity_pro.R
wget https://raw.githubusercontent.com/guertinlab/Nascent_RNA_Methods/main/insert_size.R
wget https://raw.githubusercontent.com/guertinlab/Nascent_RNA_Methods/main/pause_index.R
wget https://raw.githubusercontent.com/guertinlab/Nascent_RNA_Methods/main/exon_intron_ratio.R
wget https://raw.githubusercontent.com/guertinlab/Nascent_RNA_Methods/main/plot_all_metrics.R
wget https://raw.githubusercontent.com/guertinlab/Nascent_RNA_Methods/main/differential_expression.R

wget https://raw.githubusercontent.com/guertinlab/Nascent_RNA_Methods/main/PRO_normalization
wget https://raw.githubusercontent.com/guertinlab/Nascent_RNA_Methods/main/normalization_factor.R
wget https://raw.githubusercontent.com/guertinlab/Nascent_RNA_Methods/main/normalize_bedGraph.py

chmod +x insert_size.R
chmod +x fqComplexity
chmod +x complexity_pro.R
chmod +x pause_index.R
chmod +x exon_intron_ratio.R
chmod +x plot_all_metrics.R
chmod +x differential_expression.R

chmod +x normalize_bedGraph.py
chmod +x normalization_factor.R
chmod +x PRO_normalization

wget https://github.com/guertinlab/fqdedup/archive/refs/tags/v1.0.0.tar.gz
gunzip v1.0.0.tar.gz
tar -xvf v1.0.0.tar
cd fqdedup-1.0.0/ 
cargo build --release

wget https://hgdownload.cse.ucsc.edu/goldenpath/hg38/bigZips/hg38.fa.gz
gunzip hg38.fa.gz
bowtie2-build hg38.fa hg38

wget https://github.com/databio/ref_decoy/raw/master/human_rDNA.fa.gz
gunzip human_rDNA.fa.gz
bowtie2-build human_rDNA.fa human_rDNA

#Compute mappability for the given read length and the k-mer that corresponds to each possible read alignment position
#This is the most time-consuming step of the seqOutBias command but can be completed once before processing the sequencing data
#install from source, if you have issues: guertin@uchc.edu

# if seqOutBias is in a directory accessible by PATH, simply call it directly from the command line
seqOutBias seqtable hg38.fa --read-size=47

wget https://hgdownload.cse.ucsc.edu/goldenpath/hg38/bigZips/hg38.chrom.sizes

wget http://ftp.ensembl.org/pub/release-${release}/gtf/homo_sapiens/Homo_sapiens.GRCh38.${release}.chr.gtf.gz
gunzip Homo_sapiens.GRCh38.${release}.chr.gtf.gz

#extract all exon 1 annotations
grep 'exon_number "1"' Homo_sapiens.GRCh38.${release}.chr.gtf | \
    sed 's/^/chr/' | \
    awk '{OFS="\t";} {print $1,$4,$5,$14,$20,$7}' | \
    sed 's/";//g' | \
    sed 's/"//g' | sed 's/chrMT/chrM/g' | \
    sort -k1,1 -k2,2n > Homo_sapiens.GRCh38.${release}.tss.bed

#extract all exons
grep 'exon_number' Homo_sapiens.GRCh38.${release}.chr.gtf | \
    sed 's/^/chr/' | \
    awk '{OFS="\t";} {print $1,$4,$5,$14,$20,$7}' | \
    sed 's/";//g' | \
    sed 's/"//g' | sed 's/chrMT/chrM/g' | \
    sort -k1,1 -k2,2n > Homo_sapiens.GRCh38.${release}.all.exons.bed

#extract all complete gene annotations, sorted for use with join
awk '$3 == "gene"' Homo_sapiens.GRCh38.${release}.chr.gtf | \
    sed 's/^/chr/' | \
    awk '{OFS="\t";} {print $1,$4,$5,$10,$14,$7}' | \
    sed 's/";//g' | \
    sed 's/"//g' | sed 's/chrMT/chrM/g' | \
    sort -k5,5 > Homo_sapiens.GRCh38.${release}.bed
    
#extract all complete gene annotations, sorted for use with bedtools map
awk '$3 == "gene"' Homo_sapiens.GRCh38.${release}.chr.gtf | \
    sed 's/^/chr/' | \
    awk '{OFS="\t";} {print $1,$4,$5,$10,$14,$7}' | \
    sed 's/";//g' | \
    sed 's/"//g' | sed 's/chrMT/chrM/g' | \
    sort -k1,1 -k2,2n > Homo_sapiens.GRCh38.${release}_sorted.bed
 
#merge exon intervals that overlap each other
mergeBed -s -c 6 -o distinct -i Homo_sapiens.GRCh38.${release}.all.exons.bed | \
    awk '{OFS="\t";} {print $1,$2,$3,$4,$2,$4}' | 
    sort -k1,1 -k2,2n > Homo_sapiens.GRCh38.${release}.all.exons.merged.bed

#remove all first exons (so pause region is excluded from exon / intron density ratio)
subtractBed -s -a Homo_sapiens.GRCh38.${release}.all.exons.merged.bed -b Homo_sapiens.GRCh38.${release}.tss.bed | \
    sort -k1,1 -k2,2n > Homo_sapiens.GRCh38.${release}.no.first.exons.bed

#extract gene names of exons
intersectBed -s -wb -a Homo_sapiens.GRCh38.${release}.no.first.exons.bed -b Homo_sapiens.GRCh38.${release}.bed | \
    awk '{OFS="\t";} {print $1,$2,$3,$11,$4,$4}' | \
    sort -k1,1 -k2,2n >  Homo_sapiens.GRCh38.${release}.no.first.exons.named.bed

#extract the pause region from the first exons, position 20 - 120 downstream of the TSS
awk  '{OFS="\t";} $6 == "+" {print $1,$2+20,$2 + 120,$4,$5,$6} \
    $6 == "-" {print $1,$3 - 120,$3 - 20,$4,$5,$6}' Homo_sapiens.GRCh38.${release}.tss.bed  | \
    sort -k1,1 -k2,2n > Homo_sapiens.GRCh38.${release}.pause.bed 

#define and name all introns 
subtractBed -s -a Homo_sapiens.GRCh38.${release}.bed -b Homo_sapiens.GRCh38.${release}.all.exons.merged.bed | \
    sort -k1,1 -k2,2n > Homo_sapiens.GRCh38.${release}.introns.bed 
```

## Confirming UMI length

This is important for removing adapter steps later. Even if you know this number from your experimental protocol it doesn't hurt to confirm it in your data. Before doing any tests, subset some reads from any one of your FASTQs so these tests don't take forever to run. Make sure you are subsetting from a PE1 file!

```{r engine='bash', eval=F, echo=TRUE}
# get 4 million reads
zcat HEK_CloneZD29_30min_control_rep4_PE1_final.fastq.gz | head -n 40000000 > Z143_UMI_test.fastq

# do this in an interactive node
srun --partition=general --qos=general --mem=36G -N 1 -n 1 -c 12 --pty bash
```

**Interpreting cutadapt output**

```{r engine='bash', eval=F, echo=TRUE}
module load cutadapt

# cutadapt arguments:
# -m : minimum length
# -O : [capital letter o] minimum overlap length between adapter and read
# -a : adapter sequence ligated to 3' end, or of the first read in paired data
# -o : [lowercase o] name of output file, which is a FASTQ with trimmed reads
cutadapt --cores=12 -m 1 -O 1 -a TGGAATTCTCGGGTGCCAAGG Z143_UMI_test.fastq \
  -o Z143_UMI_test_noadapt.fastq > Z143_UMI_test_cutadapt.txt

tail Z143_UMI_test_cutadapt.txt
# 38  32011 0.0 2 28256 3368 387
# 39  1976282 0.0 2 1842220 117943 16119
# 40  81301 0.0 2 67815 12434 1052
# 41  56103 0.0 2 50968 3886 1249
# 42  45902 0.0 2 42491 2676 735
# 43  41906 0.0 2 38847 2339 720
# 44  38556 0.0 2 35661 2301 594
# 45  37035 0.0 2 34420 2048 567
# 46  43034 0.0 2 40439 2117 478
# 47  45296 0.0 2 41996 2565 735
```

Counting how many sequences follow the spike in counts (at length 39, last column): UMI length = 8.

**Trim and Align**

Another method to confirm UMI length is to trim the PE1 reads from the 5' end, one base at a time, and see when a spike in alignment rate to the human genome takes place.

```{r engine='bash', eval=F, echo=TRUE}
module load fastx

# if we didn't do this we'd just be trimming the adapter one base at a time and that's not very informative
cat Z143_UMI_test.fastq | fastx_clipper -Q 33 -a TGGAATTCTCGGGTGCCAAGG -o Z143_UMI_test_clipped.fastq

# Trim by 1 base at a time
for n in {1..9}
do
fastx_trimmer -f $(expr $n + 1) -i Z143_UMI_test_clipped.fastq -o Z143_UMI_test_clipped_trim$n.fastq
done

# -f means the first base to KEEP, so -f 2 will trim the first base (from the left/5' side)
head -2 Z143_UMI_test_clipped.fastq 
# @NB551647:99:HVY2FBGXN:1:11101:24868:1042 1:N:0:ACTTGA
# ACATAGTACTTTTAAAT
head -2 Z143_UMI_test_clipped_trim1.fastq 
# @NB551647:99:HVY2FBGXN:1:11101:24868:1042 1:N:0:ACTTGA
#  CATAGTACTTTTAAAT
head -2 Z143_UMI_test_clipped_trim2.fastq 
# @NB551647:99:HVY2FBGXN:1:11101:24868:1042 1:N:0:ACTTGA
#   ATAGTACTTTTAAAT
```

Script for aligning the clipped FASTQs:
```{r engine='bash', eval=F, echo=TRUE}
#! /usr/bin/bash
#SBATCH --job-name=ZNF143_UMI_alignments
#SBATCH -N 1                    
#SBATCH -n 1                  
#SBATCH -c 24                          
#SBATCH -p general
#SBATCH --qos=general       
#SBATCH --mem=36G                    
#SBATCH --mail-type=ALL 
#SBATCH --mail-user=jdong@uchc.edu
#SBATCH -o /home/FCAM/jdong/slurm_out/%x_%j.all_out
#SBATCH -e /home/FCAM/jdong/slurm_out/%x_%j.all_out

module load bowtie2
genome_index=/home/FCAM/jdong/human38/hg38
directory=/labs/Guertin/ZNF143_PRO
cd $directory

# simple alignment with bowtie2
for x in Z143_UMI_test_clipped*.fastq
    do
    name=$(echo $x | awk -F ".fastq" '{print $1}')
    echo "Now aligning $name"
    bowtie2 -p 24 -t -x ${genome_index} -U ${x} -S ${name}.sam
    done 2> Z143_UMI_test_clipped_stderr.txt
```

Interpreting results:
```{r engine='bash', eval=F, echo=TRUE}
grep -i "alignment rate" Z143_UMI_test_clipped_stderr.txt 
65.72% overall alignment rate # 0 bases trimmed
74.20% overall alignment rate # 1
78.63% overall alignment rate # 2
82.87% overall alignment rate # 3
84.89% overall alignment rate # 4
86.72% overall alignment rate # 5
89.22% overall alignment rate # 6
74.36% overall alignment rate # 7
95.84% overall alignment rate # 8 -- spike
96.61% overall alignment rate # 9 
```

Note the large spike in alignment rate when 8 bases are trimmed--this is another point in favor of the UMI length = 8. 


# PRO alignment and parallelization:

The following code chunk was run as "pro_processing.sh" and generally follows the PEPPRO method (https://doi.org/10.1186/s13059-021-02349-4) for PRO-seq processing and quality control assessment. 
```{r engine='bash', eval=F, echo=TRUE}
#! /usr/bin/bash

#SBATCH --job-name=pro_processing_XXXXXXX.sh
#SBATCH -N 1                  
#SBATCH -n 1                 
#SBATCH -c 24                  
#SBATCH -p general           
#SBATCH --qos=general       
#SBATCH --mem=36G               
#SBATCH --mail-type=ALL 
#SBATCH --mail-user=jdong@uchc.edu
#SBATCH -o /home/FCAM/jdong/slurm_out/%x_%j.all_out
#SBATCH -e /home/FCAM/jdong/slurm_out/%x_%j.all_out

cd /labs/Guertin/ZNF143_PRO

echo "Current wd:" $(pwd)
echo "Current node:" $(hostname)

name=XXXXXXX

module load cutadapt/3.5
module load seqtk/1.3
seqOutBias=/home/FCAM/jdong/software/seqOutBias #version 1.4.0
fqdedup=/home/FCAM/jdong/software/fqdedup
flash=/home/FCAM/jdong/software/flash
module load fastq-pair/1.0
module load samtools/1.16.1
module load genometools/1.5.10
module load ucsc_genome/2012.05.22
module load rust
module load bowtie2
module load bedtools

sizes=/home/FCAM/jdong/human38/hg38.chrom.sizes
annotation_prefix=/home/FCAM/jdong/ZNF143_PRO_2023/Homo_sapiens.GRCh38.109 
UMI_length=8
read_size=47
cores=24
genome=/home/FCAM/jdong/human38/hg38.fa
genome_index=/home/FCAM/jdong/human38/hg38
prealign_rdna_index=/home/FCAM/jdong/hum_rDNA
tallymer=/home/FCAM/jdong/ZNF143_PRO_2023/hg38.tal_${read_size}.gtTxt.gz
table=/home/FCAM/jdong/ZNF143_PRO_2023/hg38_${read_size}.4.2.2.tbl

gunzip ${name}_PE1_final.fastq.gz
gunzip ${name}_PE2_final.fastq.gz

echo 'removing dual adapter ligations and calculating the fraction of adapter/adapters in' $name
cutadapt --cores=$cores -m $((UMI_length+2)) -O 1 -a TGGAATTCTCGGGTGCCAAGG ${name}_PE1_final.fastq \
        -o ${name}_PE1_noadap.fastq --too-short-output ${name}_PE1_short.fastq > ${name}_PE1_cutadapt.txt
cutadapt --cores=$cores -m $((UMI_length+10)) -O 1 -a GATCGTCGGACTGTAGAACTCTGAAC ${name}_PE2_final.fastq \
        -o ${name}_PE2_noadap.fastq --too-short-output ${name}_PE2_short.fastq > ${name}_PE2_cutadapt.txt

PE1_total=$(wc -l ${name}_PE1_final.fastq | awk '{print $1/4}')
PE1_w_Adapter=$(wc -l ${name}_PE1_short.fastq | awk '{print $1/4}')
AAligation=$(echo "scale=2 ; $PE1_w_Adapter / $PE1_total" | bc)
echo -e  "value\texperiment\tthreshold\tmetric" > ${name}_QC_metrics.txt
echo -e "$AAligation\t$name\t0.80\tAdapter/Adapter" >> ${name}_QC_metrics.txt

echo 'removing short RNA insertions in' $name
seqtk seq -L $((UMI_length+10)) ${name}_PE1_noadap.fastq > ${name}_PE1_noadap_trimmed.fastq 

echo 'removing PCR duplicates from' $name
fqdedup -i ${name}_PE1_noadap_trimmed.fastq -o ${name}_PE1_dedup.fastq

PE1_noAdapter=$(wc -l ${name}_PE1_dedup.fastq | awk '{print $1/4}')

fastq_pair -t $PE1_noAdapter ${name}_PE1_dedup.fastq ${name}_PE2_noadap.fastq

echo 'calculating and plotting RNA insert sizes from' $name
flash -q --compress-prog=gzip --suffix=gz ${name}_PE1_dedup.fastq.paired.fq \
        ${name}_PE2_noadap.fastq.paired.fq -o ${name}

insert_size.R ${name}.hist ${UMI_length}

echo 'trimming off the UMI from' $name
seqtk trimfq -b ${UMI_length} ${name}_PE1_dedup.fastq | seqtk seq -r - > ${name}_PE1_processed.fastq
seqtk trimfq -e ${UMI_length} ${name}_PE2_noadap.fastq | seqtk seq -r - > ${name}_PE2_processed.fastq

echo 'aligning' $name 'to rDNA and removing aligned reads'
bowtie2 -p $((cores-2)) -x $prealign_rdna_index -U ${name}_PE1_processed.fastq 2>${name}_bowtie2_rDNA.log | \
        samtools sort -n - | samtools fastq -f 0x4 - > ${name}_PE1.rDNA.fastq
reads=$(wc -l ${name}_PE1.rDNA.fastq | awk '{print $1/4}')
fastq_pair -t $reads ${name}_PE1.rDNA.fastq ${name}_PE2_processed.fastq

echo 'aligning' $name 'to the genome'
bowtie2 -p $((cores-2)) --maxins 1000 -x $genome_index --rf -1 ${name}_PE1.rDNA.fastq.paired.fq \
        -2 ${name}_PE2_processed.fastq.paired.fq 2>${name}_bowtie2.log | samtools view -b - | \
        samtools sort - -o ${name}.bam

echo 'calculating rDNA alignment rate for' $name
PE1_prior_rDNA=$(wc -l ${name}_PE1_processed.fastq | awk '{print $1/4}')
PE1_post_rDNA=$(wc -l ${name}_PE1.rDNA.fastq | awk '{print $1/4}')
total_rDNA=$(echo "$(($PE1_prior_rDNA-$PE1_post_rDNA))") 
concordant_pe1=$(samtools view -c -f 0x42 ${name}.bam)
total=$(echo "$(($concordant_pe1+$total_rDNA))")
rDNA_alignment=$(echo "scale=2 ; $total_rDNA / $total" | bc)
echo -e "$rDNA_alignment\t$name\t0.10\trDNA Alignment Rate" >> ${name}_QC_metrics.txt

echo 'calculating alignment rate for' $name
map_pe1=$(samtools view -c -f 0x42 ${name}.bam)
pre_alignment=$(wc -l ${name}_PE1.rDNA.fastq.paired.fq | awk '{print $1/4}')
alignment_rate=$(echo "scale=2 ; $map_pe1 / $pre_alignment" | bc)
echo -e "$alignment_rate\t$name\t0.80\tAlignment Rate" >> ${name}_QC_metrics.txt

echo 'plotting and calculating complexity for' $name
fqComplexity -i ${name}_PE1_noadap_trimmed.fastq

echo 'calculating and plotting theoretical sequencing depth' 
echo 'to achieve a defined number of concordantly aligned reads for' $name
PE1_total=$(wc -l ${name}_PE1_final.fastq | awk '{print $1/4}')
PE1_noadap_trimmed=$(wc -l ${name}_PE1_noadap_trimmed.fastq | awk '{print $1/4}')
factorX=$(echo "scale=2 ; $PE1_noadap_trimmed / $PE1_total" | bc)
echo 'fraction of reads that are not adapter/adapter ligation products or below 10 base inserts:'
echo $factorX 
PE1_dedup=$(wc -l ${name}_PE1_dedup.fastq | awk '{print $1/4}')
factorY=$(echo "scale=2 ; $concordant_pe1 / $PE1_dedup" | bc)
fqComplexity -i ${name}_PE1_noadap_trimmed.fastq -x $factorX -y $factorY

echo 'Separating paired end reads and creating genomic BED and bigWig intensity files for' $name
seqOutBias scale $table ${name}.bam --no-scale --stranded --bed-stranded-positive \
        --bw=$name.bigWig --bed=$name.bed --out-split-pairends --only-paired \
        --tail-edge --read-size=$read_size --tallymer=$tallymer

grep -v "random" ${name}_not_scaled_PE1.bed | grep -v "chrUn" | grep -v "chrEBV" | sort -k1,1 -k2,2n > ${name}_tmp.txt 
mv ${name}_tmp.txt ${name}_not_scaled_PE1.bed 

echo 'calculating pause indices for' $name
mapBed -null "0" -s -a $annotation_prefix.pause.bed -b ${name}_not_scaled_PE1.bed | \
awk '$7>0' | sort -k5,5 -k7,7nr | sort -k5,5 -u > ${name}_pause.bed

join -1 5 -2 5 ${name}_pause.bed $annotation_prefix.bed | \
        awk '{OFS="\t";} $2==$8 && $6==$12 {print $2, $3, $4, $1, $6, $7, $9, $10}' | \
        awk '{OFS="\t";} $5 == "+" {print $1,$2+480,$8,$4,$6,$5} $5 == "-" {print $1,$7,$2 - 380,$4,$6,$5}' | \
        awk  '{OFS="\t";} $3>$2 {print $1,$2,$3,$4,$5,$6}' | sort -k1,1 -k2,2n  > ${name}_pause_counts_body_coordinates.bed
mapBed -null "0" -s -a ${name}_pause_counts_body_coordinates.bed \
        -b ${name}_not_scaled_PE1.bed | awk '$7>0' | \
        awk '{OFS="\t";} {print $1,$2,$3,$4,$5,$6,$7,$5/100,$7/($3 - $2)}' | \
        awk '{OFS="\t";} {print $1,$2,$3,$4,$5,$6,$7,$8,$9,$8/$9}' > ${name}_pause_body.bed

pause_index.R ${name}_pause_body.bed

echo 'Calculating exon density / intron density as a metric for nascent RNA purity for' $name
mapBed -null "0" -s -a $annotation_prefix.introns.bed \
        -b ${name}_not_scaled_PE1.bed | awk '$7>0' | \
        awk '{OFS="\t";} {print $1,$2,$3,$5,$5,$6,$7,($3 - $2)}' > ${name}_intron_counts.bed
mapBed -null "0" -s -a $annotation_prefix.no.first.exons.named.bed \
        -b ${name}_not_scaled_PE1.bed | awk '$7>0' | \
        awk '{OFS="\t";} {print $1,$2,$3,$4,$4,$6,$7,($3 - $2)}' > ${name}_exon_counts.bed

exon_intron_ratio.R ${name}_exon_counts.bed ${name}_intron_counts.bed

echo 'removing intermediate files'
rm ${name}_PE1_short.fastq
rm ${name}_PE2_short.fastq
rm ${name}_PE1_noadap.fastq
rm ${name}_PE2_noadap.fastq
rm ${name}_PE1_noadap_trimmed.fastq
rm ${name}_PE1_dedup.fastq
rm ${name}_PE1_processed.fastq
rm ${name}_PE2_processed.fastq
rm ${name}_PE1_dedup.fastq.paired.fq   
rm ${name}_PE2_noadap.fastq.paired.fq
rm ${name}_PE1_dedup.fastq.single.fq
rm ${name}_PE2_noadap.fastq.single.fq
rm ${name}_PE1.rDNA.fastq.paired.fq
rm ${name}_PE1.rDNA.fastq.single.fq
rm ${name}_PE2_processed.fastq.paired.fq
rm ${name}_PE2_processed.fastq.single.fq
rm ${name}.extendedFrags.fastq.gz
rm ${name}.notCombined_1.fastq.gz
rm ${name}.notCombined_2.fastq.gz

echo 'script complete'
```

## Run the previous chunk in parallel (Fig S1)

```{r engine='bash', eval=F, echo=TRUE}

file=pro_processing.sh

for i in *_PE1_final.fastq.gz
do
    nm=$(echo $i | awk -F"/" '{print $NF}' | awk -F"_PE1_final.fastq.gz" '{print $1}')
    echo $nm
    sed -e "s/XXXXXXX/${nm}/g" "$file" > pro_processing_${nm}.sh
    sbatch pro_processing_${nm}.sh
    sleep 1
done

```

Re-zip raw sequencing files:

```{r engine='bash', eval=F, echo=TRUE}
# check wildcards first
gzip *_PE1_final.fastq
gzip *_PE2_final.fastq
```

Combine all QC metrics and plot:
```{r engine='bash', eval=F, echo=TRUE}
cat *_QC_metrics.txt | awk '!x[$0]++' > project_QC_metrics.txt 

plot_all_metrics.R project_QC_metrics.txt ZNF143_degron_PRO
```

This plot is saved as `ZNF143_pro_metrics_depth_final.pdf` (Figure S1).


# Prepare input for pTA

Normalize bigWigs from seqOutBias:
```{r engine='bash', eval=F, echo=TRUE}
PRO_normalization -c hg38.chrom.sizes
```

Then merge bigWigs based on strand (control and experimental conditions together):
```{r engine='bash', eval=F, echo=TRUE}
reps=8
pair="_PE1"
name="HEK_CloneZD29_30min"
chrSizes="/Users/jinhongdong/fileRef/human38/hg38.chrom.sizes"

plusfiles=$(ls ${name}_*rep*_plus${pair}_scaled.bigWig)
bigWigMerge $plusfiles tmpPlus${pair}.bg
minusfiles=$(ls ${name}_*rep*_minus${pair}_scaled.bigWig)
bigWigMerge -threshold=-10000000000 $minusfiles tmpMinus${pair}.bg
scaleall=$(bc <<< "scale=4 ; 1.0 / $reps")
normalize_bedGraph.py -i tmpPlus${pair}.bg -s $scaleall -o ${name}_plus${pair}_scaled.bg
normalize_bedGraph.py -i tmpMinus${pair}.bg -s $scaleall -o ${name}_minus${pair}_scaled.bg
sort -k1,1 -k2,2n ${name}_plus${pair}_scaled.bg > ${name}_plus${pair}_scaled_sorted.bg
sort -k1,1 -k2,2n ${name}_minus${pair}_scaled.bg > ${name}_minus${pair}_scaled_sorted.bg
bedGraphToBigWig ${name}_plus${pair}_scaled_sorted.bg $chrSizes ${name}_plus${pair}_scaled.bigWig 
bedGraphToBigWig ${name}_minus${pair}_scaled_sorted.bg $chrSizes ${name}_minus${pair}_scaled.bigWig

rm ${name}_plus${pair}_scaled.bg
rm ${name}_minus${pair}_scaled.bg
rm ${name}_plus${pair}_scaled_sorted.bg
rm ${name}_minus${pair}_scaled_sorted.bg
rm tmpPlus${pair}.bg
rm tmpMinus${pair}.bg
```



# Prepare input for TSSinference

This is basically the same as the above, but for PE2 reads instead of PE1.

```{r engine='bash', eval=F, echo=TRUE}
reps=8
pair="_PE2"
name="HEK_CloneZD29_30min"
chrSizes="/Users/jinhongdong/fileRef/human38/hg38.chrom.sizes"

plusfiles=$(ls ${name}_*rep*_plus${pair}_scaled.bigWig)
bigWigMerge $plusfiles tmpPlus${pair}.bg
minusfiles=$(ls ${name}_*rep*_minus${pair}_scaled.bigWig)
bigWigMerge -threshold=-10000000000 $minusfiles tmpMinus${pair}.bg
scaleall=$(bc <<< "scale=4 ; 1.0 / $reps")
normalize_bedGraph.py -i tmpPlus${pair}.bg -s $scaleall -o ${name}_plus${pair}_scaled.bg
normalize_bedGraph.py -i tmpMinus${pair}.bg -s $scaleall -o ${name}_minus${pair}_scaled.bg
sort -k1,1 -k2,2n ${name}_plus${pair}_scaled.bg > ${name}_plus${pair}_scaled_sorted.bg
sort -k1,1 -k2,2n ${name}_minus${pair}_scaled.bg > ${name}_minus${pair}_scaled_sorted.bg
bedGraphToBigWig ${name}_plus${pair}_scaled_sorted.bg $chrSizes ${name}_plus${pair}_scaled.bigWig 
bedGraphToBigWig ${name}_minus${pair}_scaled_sorted.bg $chrSizes ${name}_minus${pair}_scaled.bigWig

rm ${name}_plus${pair}_scaled.bg
rm ${name}_minus${pair}_scaled.bg
rm ${name}_plus${pair}_scaled_sorted.bg
rm ${name}_minus${pair}_scaled_sorted.bg
rm tmpPlus${pair}.bg
rm tmpMinus${pair}.bg
```

## Get gene annotations

The starting file for filtering these annotations was obtained from the gencode website here: [https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_42/gencode.v42.basic.annotation.gtf.gz](https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_42/gencode.v42.basic.annotation.gtf.gz), specifically the version of basic annotation which contained reference chromosomes only. 

```{r engine='R', eval=F, echo=TRUE}
gunzip gencode.v42.basic.annotation.gtf.gz

grep 'transcript_type "protein_coding"' gencode.v42.basic.annotation.gtf | \
    grep -v 'tag "readthrough_transcript"' | \
    grep -v 'tag "RNA_Seq_supported_only"' | \
    grep -v 'tag "RNA_Seq_supported_partial"' | \
    awk '{if($3=="exon"){print $0}} ' | \
    grep -w "exon_number 1" | \
    cut -f1,4,5,7,9 | tr ";" "\t" | \
    awk '{for(i=5;i<=NF;i++){if($i~/^gene_name/){a=$(i+1)}} print $1,$2,$3,a,"na",$4}' | \
    tr " " "\t" | tr -d '"' | \
    grep -v "\tENSG" > gencode.hg38.v42.basic.firstExon.latest.filtered.bed

```

## Re-annotating transcription units after manual curation

After an initial round of transcription unit (TU) calling with TSSinference and primaryTranscriptAnnotation, we identified differentially expressed genes with DESeq2 (same methods as below) and looked at TU calls for all of the down genes in the UCSC genome browser to verify that all TSSs had been identified for each gene. We noticed some gene annotations were missing true TSSs, so they were adjusted to match the data. These are the gene annotations that were adjusted, along with accompanying browser sessions:

Plus strand genes:
- *MATR3*: TSS should be more upstream because exon1 window missed annotations with more upstream exons. (https://genome.ucsc.edu/s/jhdong/MATR3_TU)
    - new exon1 start: chr5:139274101
- delete *SRRM*: ZNF576 completely overlaps this gene and it's impossible to tell who's who (https://genome.ucsc.edu/s/jhdong/SRRM5_TU)
- *ZNF382*: The TTS looks fine, but most prominent TSS was missed by ~400bp. Update the TSS to the one in the annotation with bidir txn (https://genome.ucsc.edu/s/jhdong/ZNF382_TSS)
    - new exon1 start: chr19:36605313

Minus strand genes:
- *ATXN7L3*: a more prominent TSS is ~224bp upstream, make sure it has bidir txn (https://genome.ucsc.edu/s/jhdong/ATXN7L3_TU) 
    - manually setting exon1 boundary: chr17:44200100
- delete *DQX1*: not much bidirectional transcription at current TSS (https://genome.ucsc.edu/s/jhdong/DQX1_TU) 
- delete *NPFF*: messy overlapping genes; unsure of where to call TSS or TTS. Doesn't look like it has a proper transcription unit (https://genome.ucsc.edu/s/jhdong/NPFF_TU)

```{r engine='R', eval=F, echo=TRUE}
# import original exon1 table
oldExon1 = read.table("gencode.hg38.v42.basic.firstExon.latest.filtered.bed", sep="\t", header =FALSE)
dim(oldExon1)
# [1] 18930     6
colnames(oldExon1) = c("chr","start","end","gene", "misc","strand")

# import original transcription unit calls 
oldCoords = read.table('HEK_ZNF143_infcoords_control_only.bed', sep="\t", header =FALSE)
dim(oldCoords)
#[1] 11818     6
colnames(oldCoords) = c("chr","start","end","gene","misc","strand")

# move MATR3 exon1 start upstream
oldCoords[grepl("MATR3",oldCoords$gene),]
#       chr     start       end  gene  misc strand
# 2770 chr5 139293742 139341807 MATR3 89870      +
oldExon1[grepl("MATR3",oldExon1$gene),]
#       chr     start       end  gene misc strand
# 9188 chr5 139293722 139293778 MATR3    1      +
oldExon1[9188,"start"] = 139274101
oldExon1[grepl("MATR3",oldExon1$gene),]
#       chr     start       end  gene misc strand
# 9188 chr5 139274101 139293778 MATR3    1      +

# delete SRRM5 and DQX1
oldExon1[(oldExon1$gene %in% c("SRRM5","DQX1")),]
#         chr    start      end  gene misc strand
# 4469   chr2 74526191 74526231  DQX1    1      -
# 15528 chr19 43596617 43612088 SRRM5    1      +
oldExon1 = oldExon1[!(oldExon1$gene %in% c("SRRM5","DQX1")),]

# move ZNF382 exon1 more upstream to cut off the TSS without bidir txn
oldExon1[oldExon1$gene == c("ZNF382"),]
#         chr    start      end   gene misc strand
# 18517 chr19 36604817 36608420 ZNF382    1      +
oldExon1[oldExon1$gene == c("ZNF382"),"start"] = 36605313
oldExon1[oldExon1$gene == c("ZNF382"),]
#         chr    start      end   gene misc strand
# 18517 chr19 36605313 36608420 ZNF382    1      +

# move ATXN7L3 TSS to the upstream one with bidir txn
oldExon1[oldExon1$gene == c("ATXN7L3"),]
#        chr    start      end    gene misc strand
# 1312 chr17 44198070 44199884 ATXN7L3    1      -
oldExon1[oldExon1$gene == c("ATXN7L3"),"end"] = 44200100
oldExon1[oldExon1$gene == c("ATXN7L3"),]
#        chr    start      end    gene misc strand
# 1312 chr17 44198070 44200100 ATXN7L3    1      -

# delete NPFF
oldExon1[oldExon1$gene == c("NPFF"),]
#         chr    start      end gene misc strand
# 10590 chr12 53507483 53507484 NPFF    1      -
oldExon1 = oldExon1[!(oldExon1$gene == c("NPFF")),]

# export updated exon1 table
write.table(oldExon1, file="gencode_exon1_parsed_updated.bed",sep="\t",quote=FALSE,row.names=FALSE,col.names=FALSE)
```

The following code represents what was done with the latest gene annotations after the manual curation. 

# TSSInference

The `TSSinference.R` script can be found at: [https://github.com/guertinlab/TSSinference](https://github.com/guertinlab/TSSinference).

## Control-called TSSs 

For differential gene expression analysis, call TSSs from the control data only.

```{r engine='R', eval=F, echo=TRUE}
library(bigWig)
# source TSSinference functions
source("TSSinference.R")
# load gene annotation file
gene.exon1 = parse.bed.exon1("gencode_exon1_parsed_updated.bed")

# assign bigWig variables
# IMPORTANT: because these are PE2, switch the plus and minus bigWigs!
bw.plus='HEK_CloneZD29_30min_control_minus_PE2_scaled.bigWig'
bw.minus='HEK_CloneZD29_30min_control_plus_PE2_scaled.bigWig'

colnames(gene.exon1) = c("chrom","start","end","gene","misc","strand")
controlTSSall = TSSinference(gene.exon1, bw.plus, bw.minus,low.limit.tss.factor = 1, densityFilter = FALSE)

# get maximum TSSs for all genes
temp = controlTSSall[!is.na(controlTSSall$height),]
temp2 = temp[!(temp$chrom == "chrM"),]
controlTSSmaxH = do.call(rbind, lapply(split(temp2, as.factor(temp2$gene)), function(x) {return(x[which.max(x$height),])}))
dim(controlTSSmaxH) # 15586 genes
```

After checking TSS locations on the genome browser, ABCB1's assigned TSS turned out to be a pileup of adapters that slipped through the previous adapter removal processes, possibly due to part of the sequence being improperly called during the sequencing process.

Reassigning the "problem TSS":
These coordinates were chosen manually by selecting the read peak closest to the annotated version of ABCB1 in the genome browser that had an appreciable peak.

```{r engine='R', eval=F, echo=TRUE}
controlTSSmaxH[grepl("ABCB1",controlTSSmaxH$gene) & grepl("chr7",controlTSSmaxH$chrom),]$start = 87600883
controlTSSmaxH[grepl("ABCB1",controlTSSmaxH$gene) & grepl("chr7",controlTSSmaxH$chrom),]$end = 87600884

```

## dTAG-called TSSs 

For later analysis, also call TSSs from the ZNF143-dTAG-only data.

```{r engine='R', eval=F, echo=TRUE}
bw.minus='HEK_CloneZD29_30min_dTAGV1_plus_PE2_scaled.bigWig'
bw.plus='HEK_CloneZD29_30min_dTAGV1_minus_PE2_scaled.bigWig'

dTAGtssAll = TSSinference(gene.exon1, bw.plus, bw.minus, low.limit.tss.factor = 1,densityFilter=FALSE)
temp = dTAGtssAll[!is.na(dTAGtssAll$height),]
temp2 = temp[!(temp$chrom == "chrM"),]
dTAGtssAllmaxH = do.call(rbind, lapply( split(temp2, as.factor(temp2$gene)), function(x) {return(x[which.max(x$height),])}))
dim(dTAGtssAllmaxH) # [1] 15609     9

```


# primaryTranscriptAnnotation

Prepare specific annotations:

```{r engine='bash', eval=F, echo=TRUE}
grep 'transcript_type "protein_coding"' gencode.v42.basic.annotation.gtf | \
   awk '{if($3=="exon"){print $0}}' | \
   grep -w "exon_number 1" | \
   cut -f1,4,5,7,9 | tr ";" "\t" | \
   awk '{for(i=5;i<=NF;i++){if($i~/^gene_name/){a=$(i+1)}} print $1,$2,$3,a,"na",$4}' | \
   tr " " "\t" | tr -d '"' > gencode.v42.firstExon.bed
   
grep 'transcript_type "protein_coding"' gencode.v42.basic.annotation.gtf | \
    awk '{if($3=="transcript"){print $0}} ' | \
    cut -f1,4,5,7,9 | tr ";" "\t" | \
    awk '{for(i=5;i<=NF;i++){if($i~/^gene_name/){a=$(i+1)}} print $1,$2,$3,a,"na",$4}' | \
    tr " " "\t" | tr -d '"' > gencode.v42.transcript.bed

```

Download the pTA repository from https://github.com/WarrenDavidAnderson/genomicsRpackage/tree/master and load pTA functions from source:
```{r engine='bash', eval=F, echo=TRUE}
source("/Users/jinhongdong/software/genomicsRpackage-master/primaryTranscriptAnnotation/R/gene_ann.R")
source("/Users/jinhongdong/software/genomicsRpackage-master/primaryTranscriptAnnotation/R/map_tu.R")

```

Prepare annotation files and data:

```{r engine='R', eval=F, echo=TRUE}
# import data for all transcripts, annotate, and remove duplicate transcripts
fname = "gencode.v42.transcript.bed"
dat0 = read.table(fname,header=F,stringsAsFactors=F) 
names(dat0) = c('chr', 'start', 'end', 'gene', 'xy', 'strand') 
dat0 = unique(dat0)
gencode.transcript = dat0

chrom.sizes = read.table("/Users/jinhongdong/fileRef/human38/hg38.chrom.sizes",stringsAsFactors=F,header=F) 
names(chrom.sizes) = c("chr","size")

# load in normalized bigWigs
plus.file.pe1 = "HEK_CloneZD29_30min_control_plus_PE1_scaled.bigWig" 
minus.file.pe1 = "HEK_CloneZD29_30min_control_minus_PE1_scaled.bigWig" 
bw.plus.pe1 = load.bigWig(plus.file.pe1) 
bw.minus.pe1 = load.bigWig(minus.file.pe1)

# necessary libraries
library(NMF)
library(dplyr)
library(bigWig)
library(pracma) 
library(RColorBrewer) 
library(primaryTranscriptAnnotation)

# for each gene: get largest interval and read counts for annotated transcripts
largest.interval.bed = get.largest.interval(bed=gencode.transcript)
transcript.reads = read.count.transcript(bed=gencode.transcript, bw.plus=bw.plus.pe1, bw.minus=bw.minus.pe1)

```

Decide cutoffs for "unexpressed" genes: 
```{r engine='R', eval=F, echo=TRUE}
pdf("read_density_count.pdf", useDingbats = FALSE, width=4.2, height=4)
par(mfrow=c(1,2)) 
den.cut = -8
cnt.cut = 1
hist(log(transcript.reads$density), breaks=200,
col="black",xlab="ln(read density)",main="") 
abline(v=den.cut, col="red") 
hist(log(transcript.reads$counts), breaks=200, col="black",xlab="ln(read count)",main="") 
abline(v=cnt.cut, col="red")
dev.off()

```

Cutoffs for natural log of read density (-8) and counts (1) were determined by visual inspection of the plots. Run primaryTranscriptAnnotation to call transcription termination sites and get coordinates for each gene's transcription unit:

```{r engine='R', eval=F, echo=TRUE}
ind.cut.den = which(log(transcript.reads$density) < den.cut) 
ind.cut.cnt = which(log(transcript.reads$counts) < cnt.cut) 
ind.cut = union(ind.cut.den, ind.cut.cnt) 

# remove genes below cutoffs ("unexpressed")
unexp = names(transcript.reads$counts)[ind.cut]
largest.interval.expr.bed = largest.interval.bed[!(largest.interval.bed$gene %in% unexp),]

# get TSSs for each gene (from TSSinf)
tss.interval.bed = merge(controlTSSmaxH, largest.interval.expr.bed, by.x="gene", by.y="gene")
tss.interval.bed$end.x[tss.interval.bed$strand.x == "+"] <- tss.interval.bed$end.y[tss.interval.bed$strand.x == "+"]
tss.interval.bed$start.x[tss.interval.bed$strand.x == "-"] <- tss.interval.bed$start.y[tss.interval.bed$strand.x == "-"]
tss.interval.bed= tss.interval.bed[,c(2:4,1,5,6)]
colnames(tss.interval.bed) = c('chr', 'start', 'end', 'gene', 'xy', 'strand')
tss.interval.bed$xy <- 0

#remove gene overlaps
overlap.data = gene.overlaps( bed = tss.interval.bed ) 
# dim(overlap.data$has.start.inside) # to look inside overlap.data
# dim(overlap.data$is.a.start.inside)
# dim(overlap.data$cases)

filtered.id.overlaps = remove.overlaps(bed=tss.interval.bed,
                            overlaps=overlap.data$cases, 
                            transcripts=gencode.transcript, 
                            bw.plus=bw.plus.pe1, 
                            bw.minus=bw.minus.pe1, 
                            by="den")

# Get TTS (transcription termination site)
add.to.end = 100000
fraction.end = 0.2
dist.from.start = 50
bed.for.tts.eval = get.end.intervals(bed=filtered.id.overlaps,
                                     add.to.end=add.to.end,
                                     fraction.end=fraction.end,
                                     dist.from.start=dist.from.start)

add.to.end = max(bed.for.tts.eval$xy) 
knot.div = 40
pk.thresh = 0.05
bp.bin = 50
knot.thresh = 5

cnt.thresh = 5
tau.dist = 50000
frac.max = 1
frac.min = 0.3

inferred.coords = get.TTS(bed=bed.for.tts.eval, tss= filtered.id.overlaps,
    bw.plus=bw.plus.pe1, bw.minus=bw.minus.pe1,
    bp.bin=bp.bin, add.to.end=add.to.end,
    pk.thresh=pk.thresh, knot.thresh=knot.thresh,
    cnt.thresh=cnt.thresh, tau.dist=tau.dist,
    frac.max=frac.max, frac.min=frac.min,
    knot.div=knot.div)

final.coords = inferred.coords$bed
dim(final.coords) # [1] 13276     6

write.table(final.coords, file="HEK_ZNF143_infcoords_contrTU_20240219.bed", sep="\t", row.names=FALSE, col.names=FALSE, quote=FALSE)

```


# Differential expression analysis 

Setup and get functions:
```{r engine='R', eval=F, echo=TRUE}
library(bigWig)
library(lattice)
library(DESeq2)
library(MatchIt)
library(data.table)

source('https://raw.githubusercontent.com/guertinlab/seqOutBias/master/docs/R/seqOutBias_functions.R')
source('https://raw.githubusercontent.com/mjg54/znf143_pro_seq_analysis/master/docs/ZNF143_functions.R')

# Required functions in addition to sourced functions from above:

# Overwrite get.raw.counts.interval in ZNF143_functions.R (just changes the hard-coded file suffixes)

get.raw.counts.interval <- function(df, path.to.bigWig, file.prefix = 'M') {
    vec.names = c()
    inten.df=data.frame(matrix(ncol = 0, nrow = nrow(df)))
    
    for (mod.bigWig in Sys.glob(file.path(path.to.bigWig, paste(file.prefix, "*plus_PE1.bigWig", sep ='')))) {
        factor.name = strsplit(strsplit(mod.bigWig, "/")[[1]][length(strsplit(mod.bigWig, "/")[[1]])], '_plus')[[1]][1]
        print(factor.name)
        vec.names = c(vec.names, factor.name)
        loaded.bw.plus = load.bigWig(mod.bigWig)
        print(mod.bigWig)
        print(paste(path.to.bigWig,'/',factor.name, '_minus.bigWig', sep=''))
        loaded.bw.minus = load.bigWig(paste(path.to.bigWig,'/',factor.name, '_minus_PE1.bigWig', sep=''))
        mod.inten = bed6.region.bpQuery.bigWig(loaded.bw.plus, loaded.bw.minus, df)
        inten.df = cbind(inten.df, mod.inten)
    }
    colnames(inten.df) = vec.names
    r.names = paste(df[,1], ':', df[,2], '-', df[,3],'_', df[,4], sep='')
    row.names(inten.df) = r.names
    return(inten.df)
}

# run.deseq.list.dds: new function
run.deseq.list.dds <- function(mat) {
  sample.conditions = factor(c("untreated","untreated","untreated","untreated","treated","treated","treated","treated"), levels=c("untreated","treated"))        
  deseq.counts.table = DESeqDataSetFromMatrix(mat, DataFrame(sample.conditions), ~ sample.conditions);
  colData(deseq.counts.table)$condition<-factor(colData(deseq.counts.table)$sample.conditions, levels=c('untreated','treated'));
  dds = DESeq(deseq.counts.table);
  #res = results(dds);
  #res = res[order(res$padj),];
  return(dds)
}

# tighten_summit_window: new function. Needed for categorizing genes
tighten_summit_window <- function(res.deseq) {
  chr = sapply(strsplit(rownames(res.deseq), ':'), '[', 1)
  start = as.numeric(sapply(strsplit(sapply(strsplit(rownames(res.deseq), ':'), '[', 2), "-"), "[", 1))
  x=sapply(strsplit(sapply(strsplit(rownames(res.deseq), ':'), '[', 2), "-"), "[", 2)
  end = as.numeric(sapply(strsplit(x, "_"), "[", 1))
  gene = sapply(strsplit(rownames(res.deseq), "_"), "[", 2)
  df = cbind.data.frame(chr, start, end, gene)
  return(df)
}

plotPCAlattice <- function(df, file = 'PCA_lattice.pdf') {  
  perVar = round(100 * attr(df, "percentVar"))
  df = data.frame(cbind(df, sapply(strsplit(as.character(df$name), '_rep'), '[', 1)))
  colnames(df) = c(colnames(df)[1:(ncol(df)-1)], 'unique_condition')
  print(df)
  #get colors and take away the hex transparency
  color.x = substring(rainbow(length(unique(df$unique_condition))), 1,7) 
  
  df$color = NA
  df$alpha.x = NA
  df$alpha.y = NA
  df$colpal = NA
  
  for (i in 1:length(unique(df$unique_condition))) {
    
    df[df$unique_condition == unique(df$unique_condition)[[i]],]$color = color.x[i]   
    #gives replicates for unique condition
    reps_col<- df[df$unique_condition == unique(df$unique_condition)[[i]],]
    #gives number of replicates in unique condition
    replicates.x = nrow(reps_col)
    alx <- rev(seq(0.2, 1, length.out = replicates.x))
    
    #count transparency(alx), convert alx to hex(aly), combain color and transparency(cp)
    for(rep in 1:replicates.x) {
    
      na <- reps_col[rep, ]$name
      df[df$name == na, ]$alpha.x = alx[rep]
      aly = as.hexmode(round(alx * 255))
      df[df$name == na, ]$alpha.y = aly[rep]
      cp = paste0(color.x[i], aly)
      df[df$name == na, ]$colpal = cp[rep]
      #print(df)
    }
  }
  colpal = df$colpal
  df$name = gsub('_', ' ', df$name)
  pdf(file, width=6, height=6, useDingbats=FALSE)
  print(xyplot(PC2 ~ PC1, groups = name, data=df,
               xlab = paste('PC1: ', perVar[1], '% variance', sep = ''),
               ylab = paste('PC2: ', perVar[2], '% variance', sep = ''),
               par.settings = list(superpose.symbol = list(pch = c(20), col=colpal)),
               pch = 20, cex = 1.7,
               auto.key = TRUE,
               col = colpal))
  dev.off()
}

```

## DESeq2 analysis and MA plot (Fig. 3A): 

```{r engine='R', eval=F, echo=TRUE}
inferred.coords = final.coords

# use unnormalized bigWigs and get size factors from DESeq2
counts.df = abs(get.raw.counts.interval(inferred.coords, "/Users/jinhongdong/Desktop/TSSinference/ZNF143dTag_2023/seqOutBias_bw", file.prefix = "HEK_CloneZD29"))
estimateSizeFactorsForMatrix(counts.df)


# check PCA 
dds = run.deseq.list.dds(counts.df) 
rld <- rlog(dds)
pca.plot = plotPCA(rld, intgroup="sample.conditions", returnData=TRUE)
pca.plot$sample.conditions = rownames(pca.plot)
plotPCAlattice(pca.plot, file = 'PCA_ZNF143_PRO_contrTU_20240220.pdf') 

# run DESeq
rep = factor(sapply(strsplit(colnames(counts.df), 'rep'), '[', 2))
sample.conditions = factor(c("untreated","untreated","untreated","untreated","treated","treated","treated","treated"), levels=c("untreated","treated"))
deseq.df = DESeqDataSetFromMatrix(counts.df, cbind.data.frame(sample.conditions, rep), ~ rep + sample.conditions)
deseq.df = DESeq(deseq.df)

# Categorize genes into activated (up) and repressed (down)
upRS = res.deseq[res.deseq$padj < 0.1 & !is.na(res.deseq$padj) & res.deseq$log2FoldChange > 0,]
upRS.strand = merge(cbind(tighten_summit_window(activated), "Up"), inferred.coords, by.x = "gene", by.y = "gene")[,c(2, 3, 4, 1, 5, 10)]  
write.table(upRS.strand, file = paste0('ZNF143dTAG_up_genes_20240220.bed'), quote = FALSE, row.names = FALSE, col.names = FALSE, sep = '\t')

downRS = res.deseq[res.deseq$padj < 0.1 & !is.na(res.deseq$padj) & res.deseq$log2FoldChange < 0,]
downRS.strand = merge(cbind(tighten_summit_window(repressed), "Down"), inferred.coords, by.x = "gene", by.y = "gene")[,c(2, 3, 4, 1, 5, 10)] 
write.table(downRS.strand, file = paste0('ZNF143dTAG_down_genes_20240220.bed'), quote = FALSE, row.names = FALSE, col.names = FALSE, sep = '\t')

dim(upRS) # 182
upRScoords = tighten_summit_window(upRS)

dim(downRS) # 365
downRScoords = tighten_summit_window(downRS)

# Get matched (on baseMean) unchanged genes for up and down genes
unchanged = res.deseq[!is.na(res.deseq$padj) & res.deseq$padj > 0.1 & abs(res.deseq$log2FoldChange) < 0.01,]
unchanged$treatment = 0
upRS$treatment = 1
df.deseq.effects.lattice = rbind(unchanged, upRS) 
out = matchit(treatment ~ baseMean, data = df.deseq.effects.lattice, method = "optimal", ratio = 1) 
unchanged = df.deseq.effects.lattice[rownames(df.deseq.effects.lattice) %in% out$match.matrix,] 
unchanged.strand = merge(cbind(tighten_summit_window(unchanged), "Matched to Up"), inferred.coords, by.x = "gene", by.y = "gene")[,c(2, 3, 4, 1, 5, 10)] 
write.table(unchanged.strand, file = paste0('ZNF143dTAG_up_matched_genes_20240220.bed'), quote = FALSE, row.names = FALSE, col.names = FALSE, sep = '\t')

unchanged$treatment = "Matched to Up"
upRS$treatment = "Up"
dfRS = rbind(upRS, unchanged)

unchanged = res.deseq[!is.na(res.deseq$padj) & res.deseq$padj > 0.1 & abs(res.deseq$log2FoldChange) < 0.01,]
unchanged$treatment = 0
downRS$treatment = 1
df.deseq.effects.lattice = rbind(unchanged, downRS)
out = matchit(treatment ~ baseMean, data = df.deseq.effects.lattice, method = "optimal", ratio = 1)
unchanged = df.deseq.effects.lattice[rownames(df.deseq.effects.lattice) %in% out$match.matrix,]
unchanged.strand = merge(cbind(tighten_summit_window(unchanged), "Matched to Down"), inferred.coords, by.x = "gene", by.y = "gene")[,c(2, 3, 4, 1, 5, 10)] 
write.table(unchanged.strand, file = paste0('ZNF143dTAG_down_matched_genes_20240220.bed'), quote = FALSE, row.names = FALSE, col.names = FALSE, sep = '\t')

unchanged$treatment = "Matched to Down"
downRS$treatment = "Down"
dfRS = rbind(dfRS, unchanged)
dfRS = rbind(dfRS, downRS)
dfRS$design = "rep+SC"
dfRScoords = tighten_summit_window(dfRS)
dfRS = cbind(dfRScoords,dfRS)

# Add information about matched status and category into DESeq results table
resRSdeseq = res.deseq
deseqCoords = tighten_summit_window(resRSdeseq)
resRSdeseq = cbind(deseqCoords,resRSdeseq)
resRSdeseq$cat = "Other"
resRSdeseq[resRSdeseq$gene %in% upRScoords$gene,]$cat = "Up"
resRSdeseq[resRSdeseq$gene %in% downRScoords$gene,]$cat = "Down"

resRSdeseq$matchUp = "No"
resRSdeseq[resRSdeseq$gene %in% dfRS[dfRS$treatment == "Matched to Up",]$gene,]$matchUp = "Yes"

resRSdeseq$matchDown = "No"
resRSdeseq[resRSdeseq$gene %in% dfRS[dfRS$treatment == "Matched to Down",]$gene,]$matchDown = "Yes"

deseqAll = resRSdeseq
deseqAll$fullCatRS = paste(deseqAll$catRS,deseqAll$matchUpRS,deseqAll$matchDownRS,sep=".")

# What the full categories mean:
# - Up.No.No = up gene (pink) 
# - Other.Yes.No = matched to up gene (dark grey) 
# - Down.No.No = down gene (blue) 
# - Other.No.Yes = matched to down gene (dark grey) 
# - Other.Yes.Yes or Other.No.No = other gene (light grey) 

deseqAll_strand = merge(deseqAll, inferred.coords[,c(4,6)], by="gene") 
deseqAll2 = deseqAll_strand[,c(2:4,1,5,28,6:27)]
write.table(deseqAll_strand[,c(2:4,1,5,28,6:27)],file="deseqAll_20240220.txt",sep="\t",row.names=FALSE,col.names=FALSE,quote=FALSE)

# Make MA plot
levelsMA = c("Other.Yes.Yes","Other.No.No","Other.Yes.No", "Other.No.Yes","Up.No.No","Down.No.No")
deseqAll$fullCatRS = factor(deseqAll$fullCatRS, levels = levelsMA)

pdf("MAplot_deseq_ZNF143pro_20240220.pdf", useDingbats = FALSE, width=3.83, height=3.83)
xyplot(deseqAll$log2FoldChangeRS ~ log(deseqAll$baseMeanRS, base=10),
    groups=deseqAll$fullCatRS,
    col=c("grey90","grey90","grey30","grey30","#ce228e" ,"#2290cf"),
    main="Differential Expression\nrep + sample.condition", scales="free", aspect=1, pch=20, cex=0.5,
    ylab=expression("log"[2]~"PRO-seq fold change"), 
    xlab=expression("log"[10]~"Mean of Normalized Counts"),
    par.settings=list(par.xlab.text=list(cex=1.1,font=2), 
                        par.ylab.text=list(cex=1.1,font=2)))
dev.off()

```


# Make integrated UCSC tracks for genome browser viewing

For easier viewing, create genome browser tracks with signals integrated along the entire read:

https://raw.githubusercontent.com/guertinlab/znf143_degron/main/PRO_analysis/pro_ucsc.sh
https://raw.githubusercontent.com/guertinlab/znf143_degron/main/PRO_analysis/pro_ucsc_2.sh

The resulting PRO-seq tracks are available on our trackhub, available on the UCSC genome browser by connecting to: `http://guertinlab.cam.uchc.edu/ znf143_hub/hub.txt`.

# Infer regulatory elements using bidirectional TXN

Regulatory regions were inferred with dREG's web portal (https://dreg.js2.scigap.org).
The output was analyzed according to the following script: 

https://raw.githubusercontent.com/guertinlab/znf143_degron/main/PRO_analysis/dREG/ZNF143_dREG_analysis.R
```{r engine='bash', eval=F, echo=TRUE}
awk '{OFS="\t";} {print $1,$2,$6}' ZNF143_total.dREG.peak.full.bed > ZNF143_total.dREG.peak.minus.bed
awk '{OFS="\t";} {print $1,$6,$3}' ZNF143_total.dREG.peak.full.bed > ZNF143_total.dREG.peak.plus.bed

```

# Detour to ChIP-seq analysis 

Please see ChIP-seq analysis vignette (https://guertinlab.github.io/znf143_degron/ChIP_analysis/Sathyan_ChIP_analysis.html) for processing of ZNF143-dTAG ChIP-seq samples and identification of functional ZNF143 binding sites.

# Make CDF of ZNF143 binding sites vs. up/down genes (Fig. 3B)

Uses the previously identified ZNF143 binding sites and plots their distance to up and down genes in a cumulative distribution function.

Key inputs:

- gene file: deseqAll_20240220.txt
- Binding sites: ZNF143strict_comp29_inferredSites_peakIntensities_unique.bed 

```{r engine='R', eval=F, echo=TRUE}
source('https://raw.githubusercontent.com/guertinlab/seqOutBias/master/docs/R/seqOutBias_functions.R')
source('https://raw.githubusercontent.com/mjg54/znf143_pro_seq_analysis/master/docs/ZNF143_functions.R')
source('https://raw.githubusercontent.com/guertinlab/genex/main/ChIP_analysis/cdf_functions.R')

bedTools.closest <- function(functionstring="/usr/local/bin/bedtools2-2.31.0/bin/closestBed",bed1,bed2,opt.string="") {
  
  options(scipen =99) # not to use scientific notation when writing out
  
  #write bed formatted dataframes to tempfile
  write.table(bed1,file= 'a.file.bed', quote=F,sep="\t",col.names=F,row.names=F)
  write.table(bed2,file= 'b.file.bed', quote=F,sep="\t",col.names=F,row.names=F)
  
  # create the command string and call the command using system()
  command1=paste('sort -k1,1 -k2,2n', 'a.file.bed', '> a.file.sorted.bed')
  cat(command1,"\n")
  try(system(command1))
  command2=paste('sort -k1,1 -k2,2n', 'b.file.bed', '> b.file.sorted.bed')
  cat(command2,"\n")
  try(system(command2))
  
  # use opt.string argument to add options for closestBed
  command=paste(functionstring,opt.string,"-a",'a.file.sorted.bed',"-b",'b.file.sorted.bed',">",'out.file.bed',sep=" ")
  cat(command,"\n")
  try(system(command))
  
  res=read.table('out.file.bed',sep ="\t", header=F, comment.char='')
  
  command3=paste('rm', 'a.file.bed', 'b.file.bed', 'a.file.sorted.bed', 'b.file.sorted.bed', 'out.file.bed')
  cat(command3,"\n")
  try(system(command3))
  
  colnames(res) = c(colnames(bed1), colnames(bed2), 'disMOTIFcTSS' )
  return(res)
}

znf143binding = read.table(file = "./motif_analysis_201/ZNF143strict_comp29_inferredSites_peakIntensities_unique.bed", sep="\t", header=FALSE)
colnames(znf143binding) = c("chrMotif","startMotif","endMotif","motif","peakIntens","strandMotif")

bed.tss = get.tss(deseqAll2) 
colnames(bed.tss) = c("cTSSchr","cTSSstart","cTSSend","gene","baseMeanRS","strand")
write.table(bed.tss,file="controlCalledTSS_20240222.bed",row.names=FALSE,col.names=FALSE,sep="\t",quote=FALSE)
identical(bed.tss$gene,deseqAll$gene) # TRUE
distances = bedTools.closest(bed1 = bed.tss, bed2 = znf143binding, opt.string = '-D a')
deseqAlldist = merge(deseqAll2,distances[,c(1:4,7:13)],by="gene")

plot_cdf <- function(df.all, tf="quantile", cat = "Repressed", col.lines = c("#ce228e", "grey60", "#2290cf","grey90"), line.type = c(1), cex = 1, abline=1) {
pdf(paste0(tf, "_CDF_", cat, ".pdf"), width=6.2, height=3.83) 
         print(ecdfplot(~log(abs(disMOTIFcTSS), base = 10), groups = fullCatRS, data = df.all,
         auto.key = list(lines=TRUE, points=FALSE, cex = cex),
         col = col.lines,
         aspect = 1,
                                        #xlim = c(0, 50000),
         scales=list(relation="free",alternating=c(1,1,1,1)),
         ylab = 'Cumulative Distribution Function',
         xlab = expression('log'[10]~'ZNF143 inferred binding site distance from TSS'),
                                        #index.cond = list(c(2,1)),
         between=list(y=1.0),
         type = 'a',
         xlim = c(0,8),
         lwd=2,
         lty=line.type,
         par.settings = list(superpose.line = list(col = col.lines, lwd=3), strip.background=list(col="grey85")),
         panel = function(...) {
             panel.abline(v= log(abline, base=10), lty =2) # variable line location
             panel.ecdfplot(...)
         }))
    dev.off()
}

trimmed2 = deseqAlldist[(deseqAlldist$fullCatRS != "Other.No.No"),]
trimmed2 = droplevels(trimmed2)

matchedDown = deseqAlldist[deseqAlldist$matchDownRS == "Yes",] 
matchedDown$cdfCAT = "Matched to Down"
matchedUp = deseqAlldist[deseqAlldist$matchUpRS == "Yes",]
matchedUp$cdfCAT = "Matched to Up"
downCDF = deseqAlldist[deseqAlldist$catRS == "Down",]
downCDF$cdfCAT = "Down"
upCDF = deseqAlldist[deseqAlldist$catRS == "Up",]
upCDF$cdfCAT = "Up"

plotCDFrs = rbind(matchedDown,matchedUp,downCDF,upCDF)
plotCDFrs$cdfCAT = factor(plotCDFrs$cdfCAT,levels=c("Matched to Down","Matched to Up","Down","Up"))

col.lines=c("grey80","grey60","#2290cf","#ce228e")

pdf("RS_CDF_20240304.pdf", width=6.2, height=3.83) 
ecdfplot(~log(abs(disMOTIFcTSS), base = 10), groups = cdfCAT, 
    data = plotCDFrs,
    auto.key = list(lines=TRUE, points=FALSE, cex = 1),
    col = col.lines,
    aspect = 1,
                                #xlim = c(0, 50000),
    scales=list(relation="free",alternating=c(1,1,1,1), axs="i"),
    ylab = 'Cumulative Distribution Function',
    xlab = expression('log'[10]~'ZNF143 inferred binding site distance from TSS'),
                                #index.cond = list(c(2,1)),
    between=list(y=1.0),
    type = 'a',
    xlim = c(0,6.5),
    ylim = c(0,1.0),
    lwd=2,
    lty=line.type,
    par.settings = list(superpose.line = list(col = col.lines, lwd=3), strip.background=list(col="grey85")),
    panel = function(...) {
        panel.abline(v= log(500, base=10), lty =2) # variable line location
        panel.ecdfplot(...)
    })
dev.off()

```


# deepTools heatmap (Fig. 3C)

```{r engine='bash', eval=F, echo=TRUE}
# Generate input bigWigs
awk '{OFS="\t";} {print $1,$2,$3,$5}' ZNF143strict_comp29_inferredSites_peakIntensities_unique.bed > ZNF143strict_comp29_inferredSites_peakIntensities_unique.bedGraph
sizes=/Users/jinhongdong/fileRef/human38/hg38.chrom.sizes
wigToBigWig -clip ZNF143strict_comp29_inferredSites_peakIntensities_unique.bedGraph $sizes ZNF143strict_comp29_inferredSites_peakIntensities_unique.bigWig

# Create heatmap with custom color gradient
computeMatrix reference-point --referencePoint TSS -b 500 -a 500 -p 7 --missingDataAsZero \
  -R ZNF143dTAG_down_genes_20240220_repSC.bed ZNF143dTAG_up_genes_20240220_repSC.bed --binSize 1 \
  -S ./motif_analysis_201/ZNF143strict_comp29_inferredSites_peakIntensities_unique.bigWig \
  -o matrix_HA_ChIP_ZNF143_peaks_diffExp_TSS.gz --outFileSortedRegions ZNF143_TSS_computeMatrix_outRegions.bed

customBright="#000004FF,#ff9147,#ff9d45,#ffa944,#ffb543,#ffc144,#ffcd46,#ffd949,#ffe54e,#fef155,#fbfd5d,#fbfd5d,#eaf951,#d8f546,#c5f13b,#b2ed31,#9ce927,#85e51f,#6be018,#4adc15,#00d715,#00d715,#00de49,#00e46b,#00e988,#00eea2,#00f3ba,#00f6d0,#24fae2,#53fdf2,#75ffff"

plotHeatmap -m matrix_HA_ChIP_ZNF143_peaks_diffExp_TSS_20240328.gz -out heatmap_HA_ChIP_ZNF143_motifs.pdf \
    --heatmapHeight 7 --zMax 5000 --linesAtTickMarks \
    --regionsLabel "dTAG Repressed" "dTAG Activated" --xAxisLabel "Distance from TSS" --dpi 500 \
    --samplesLabel "ZNF143 motif locations" --colorList ${customBright} --whatToShow "heatmap and colorbar"

```

# Compartment modeling (Fig. 3D)

For the scripts mentioned in this section, please see the repository for our updated compartment model, which contains a vignette and functions [https://github.com/guertinlab/compartment_model](https://github.com/guertinlab/compartment_model). The vignette was followed to create Fig. 3D in the ZNF143 manuscript. 

The following code is to generate the inputs for the compartment model:

```{r engine='R', eval=F, echo=TRUE}
source("pause_workflow_funcs_v2.R") # from guertinlab/compartment_model/R/ on Github

bw.cntrl.plus = load.bigWig('HEK_CloneZD29_30min_control_plus_PE1_scaled.bigWig')
bw.cntrl.minus = load.bigWig('HEK_CloneZD29_30min_control_minus_PE1_scaled.bigWig')

bw.cond1.plus = load.bigWig('HEK_CloneZD29_30min_dTAGV1_plus_PE1_scaled.bigWig')
bw.cond1.minus = load.bigWig('HEK_CloneZD29_30min_dTAGV1_minus_PE1_scaled.bigWig')

pTA = deseqAlldist[,c(2,3,4,1,5,6)]
write.table(deseqAlldist[,c(2,3,4,1,5,6)],file="inferred_transcript_units_ZNF143_PRO.bed",sep="\t",quote=FALSE,row.names=FALSE,col.names=FALSE)
df.pause.body <- find.pause.regions(pTA,bw.cntrl.plus,bw.cntrl.minus)
rownames(df.pause.body) = df.pause.body$gene

merged.pbody.dtagv1.vs.control = merge(df.pause.body, deseqAlldist[,c(2,3,4,1,5,6,12)])
merged.pbody.dtagv1.vs.control = merged.pbody.dtagv1.vs.control[,c(colnames(df.pause.body),colnames(deseqAlldist[,c(2,3,4,1,5,6,12)]))]

bedOut = deseqAlldist[,c(2,3,4,1,5,6,12)]
colnames(bedOut) = c("chr","start","end","gene","baseMean","strand","treatment")
saveRDS(bedOut,file="ZNF143_pro_deseq_categories.bed")

run.plotting.steps(merged.pbody.dtagv1.vs.control, "Control", bw.cntrl.plus, bw.cntrl.minus, "ZNF143_dTAGV1", bw.cond1.plus, bw.cond1.minus, "ZNF143_dTAGV1 (all genes)", color.names=c(rgb(1,0,0,1/2), rgb(0,0,1,1/2)))
# output:
# [1] "saved composite.ZNF143_dTAGV1.v.Control.rds"
# [1] "will use 3.510542 as ylimit"
# [1] "saved composite_PolII_density_around_ZNF143_dTAGV1 (all genes)_genes_ZNF143_dTAGV1.v.Control.pdf"
# [1] "saved density.ZNF143_dTAGV1.v.Control.rds"
# [1] "box-whisker-violin: setting min(ylim): -3.734154, max(ylim): 3.703059"
# [1] "saved pause.index.fc.ZNF143_dTAGV1.v.Control.pdf"

density.obj = readRDS("density.ZNF143_dTAGV1.v.Control.rds")

# down genes only
repressed.baseline = subset(density.obj, cond == "Control" & catRS == "Down")
dim(repressed.baseline) #[1] 365  21
repressed.treatment = subset(density.obj, cond == "ZNF143_dTAGV1" & catRS == "Down")
dim(repressed.treatment) # [1] 365  21
colNames = c("gene", "pause_sum", "body_avg")
write.table(repressed.baseline[,colNames], "ZNF143_dTAGV1_down_baseline.txt",  sep="\t", quote=F, row.names=F)
write.table(repressed.treatment[,colNames], "ZNF143_dTAGV1_down_treatment.txt",  sep="\t", quote=F, row.names=F)

```

Rudradeep Mukherjee ran the model and plotted the results (`combinedResults.txt.gz`) with the following code chunk:

```{r engine='R', eval=F, echo=TRUE}
library(dplyr)
library(ggplot2)
library(scales)

combined_df = read.table("/Users/rudradeepmukherjee/Documents/UConn Health/comparment.model.project/datasets, genome/ZNF143_Data/Jinhong/combinedResults.txt", sep="\t", header=T)

combined_df$kinit_FC = combined_df$initiation_ZNF143_dTAGv1 / combined_df$initiation_baseline
combined_df$krel_FC = combined_df$pauseRelease_ZNF143_dTAGv1 / combined_df$pauseRelease_baseline

summary.combined_df = combined_df %>% group_by(gene) %>% summarise_at(c("kinit_FC", "krel_FC"), c("mean", "min", "max", "median"))

ggplot(summary.combined_df) + 
        geom_violin(aes(x="Initiation", y = kinit_FC_median), scale="width") + 
        geom_violin(aes(x="Pause Release", y = krel_FC_median), scale="width") +
        geom_boxplot(aes(x="Initiation", y = kinit_FC_median), width = 0.3, alpha=0.3) + 
        geom_boxplot(aes(x="Pause Release", y = krel_FC_median), width = 0.3, alpha=0.3) +
        geom_point(aes(x="Initiation", y = kinit_FC_median), position="jitter", alpha=0.2) + 
        geom_point(aes(x="Pause Release", y = krel_FC_median), position="jitter", alpha=0.2) +
          
        scale_y_continuous(trans=log10_trans(),
                breaks=trans_breaks('log10', function(x) 10^x),
                labels=trans_format('log10', math_format(.x))) + ylab(expression(log[10] ~ "median foldchange")) +
             theme_bw() + fontTheme
ggsave("ZNF143_median_foldchange.pdf") # Fig 3D

```

# Identifying shifting TSSs

```{r engine='R', eval=F, echo=TRUE}
# Add control-called TSSs (cTSS) and dTAG-called TSSs (dTSS) into 
# the table with all DESeq results and gene categorizations
colnames(dTAGtssAllmaxH) = c("dTSSchr","dTSSstart","dTSSend","gene","misc","strand","dTSSheight","dTSSupDens","dTSSdownDens")
deseqAlldistTSSs = merge(deseqAlldist,dTAGtssAllmaxH[,c("dTSSchr","dTSSstart","dTSSend","gene","dTSSheight","dTSSupDens","dTSSdownDens")],by="gene",all.x=TRUE)

colnames(controlTSSmaxH) = c("cTSSchr","cTSSstart","cTSSend","gene","misc","strand","cTSSheight","cTSSupDens","cTSSdownDens")
deseqAlldistTSSconds = merge(deseqAlldistTSSs,controlTSSmaxH[,c("gene","cTSSheight","cTSSupDens","cTSSdownDens")],by="gene",all.x=TRUE)

# distances from nearest ZNF143 motif to the dTSSs: disMOTIFdTSS
bedTools.closest <- function(functionstring="/usr/local/bin/bedtools2-2.31.0/bin/closestBed",bed1,bed2,opt.string="",distLabel = "dis") {
  
  options(scipen =99) # not to use scientific notation when writing out
  
  #write bed formatted dataframes to tempfile
  write.table(bed1,file= 'a.file.bed', quote=F,sep="\t",col.names=F,row.names=F)
  write.table(bed2,file= 'b.file.bed', quote=F,sep="\t",col.names=F,row.names=F)
  
  # create the command string and call the command using system()
  command1=paste('sort -k1,1 -k2,2n', 'a.file.bed', '> a.file.sorted.bed')
  cat(command1,"\n")
  try(system(command1))
  command2=paste('sort -k1,1 -k2,2n', 'b.file.bed', '> b.file.sorted.bed')
  cat(command2,"\n")
  try(system(command2))
  
  # use opt.string argument to add options for closestBed
  command=paste(functionstring,opt.string,"-a",'a.file.sorted.bed',"-b",'b.file.sorted.bed',">",'out.file.bed',sep=" ")
  cat(command,"\n")
  try(system(command))
  
  res=read.table('out.file.bed',sep ="\t", header=F, comment.char='')
  
  command3=paste('rm', 'a.file.bed', 'b.file.bed', 'a.file.sorted.bed', 'b.file.sorted.bed', 'out.file.bed')
  cat(command3,"\n")
  try(system(command3))
  
  colnames(res) = c(colnames(bed1), colnames(bed2), distLabel )
  return(res)
}

bed.tss = deseqAlldistTSSconds[!is.na(deseqAlldistTSSconds$dTSSchr),c("dTSSchr","dTSSstart","dTSSend","gene","baseMeanRS","strand")]
distances = bedTools.closest(bed1 = bed.tss, bed2 = znf143binding, opt.string = '-D a', distLabel = "disMOTIFdTSS")
colnames(distances) = c("dTSSchr","dTSSstart", "dTSSend", "gene", "baseMeanRS", "strand", "chrMotifDT", "startMotifDT","endMotifDT","motifDT", "peakIntensDT", "strandMotifDT","disMOTIFdTSS")

# Merge back into giant table
znf143genesDF = merge(deseqAlldistTSSconds,distances[,c("gene","chrMotifDT", "startMotifDT","endMotifDT","motifDT", "peakIntensDT", "strandMotifDT","disMOTIFdTSS")],by="gene", all.x=TRUE)

```

## Find fraction of genes with shifted max TSS locations (Fig. 3E barchart)

```{r engine='R', eval=F, echo=TRUE}
# Create coords cols for cTSS and dTSS 
znf143genesDF$cTSScoords = paste0(znf143genesDF$cTSSchr,":",znf143genesDF$cTSSstart,"-",znf143genesDF$cTSSend)
znf143genesDF$dTSScoords = paste0(znf143genesDF$dTSSchr,":",znf143genesDF$dTSSstart,"-",znf143genesDF$dTSSend)

# Categorize by presence/absence of TSS shift
znf143genesDF$TSSshift = "No"
znf143genesDF$TSSshift[znf143genesDF$cTSScoords != znf143genesDF$dTSScoords] = "Yes"

# Number of down promo genes that have a shifting max TSS: 
dim(znf143genesDF[znf143genesDF$catRS == "Down" & abs(znf143genesDF$disMOTIFcTSS) < 500 & znf143genesDF$disMOTIFcTSS < 0 & znf143genesDF$TSSshift == "Yes",])
# 119 out of 292 = 40.7% 

# Match unchanged genes on control TSS heights
znf143genesDF$catRS[znf143genesDF$log2FoldChangeRS < 0.01 & znf143genesDF$log2FoldChangeRS > -0.01 & znf143genesDF$padjRS > 0.1] = "Unchanged" 
# 1430 unchanged genes

unchanged = znf143genesDF[znf143genesDF$catRS == "Unchanged" & abs(znf143genesDF$disMOTIFcTSS) > 500,]
unchanged$treatment = 0
down500promo = znf143genesDF[znf143genesDF$catRS == "Down" & znf143genesDF$disMOTIFdTSS > -500 & znf143genesDF$disMOTIFcTSS < 0,]
down500promo$treatment = 1
df.deseq.effects.lattice = rbind(unchanged, down500promo) # SAVE WORKSPACE 
out = matchit(treatment ~ cTSSheight, data = df.deseq.effects.lattice[!is.na(df.deseq.effects.lattice$cTSSheight),], method = "optimal", ratio = 1)
cTSSmatches = df.deseq.effects.lattice[rownames(df.deseq.effects.lattice) %in% out$match.matrix,]
znf143genesDF$matchDownPromoCTSS = znf143genesDF$gene %in% cTSSmatches$gene

# Matched unchanged genes with shifting TSSs 
dim(znf143genesDF[znf143genesDF$matchDownPromoCTSS == TRUE & znf143genesDF$TSSshift == "Yes",])
# [1] 57 66
dim(znf143genesDF[znf143genesDF$matchDownPromoCTSS == TRUE,])
# [1] 292  66 # 57/292 = 19.5 % 

# How many unchanged genes overall have shifted TSSs?
dim(znf143genesDF[znf143genesDF$catRS == "Unchanged" & abs(znf143genesDF$disMOTIFcTSS) > 500 & znf143genesDF$TSSshift == "Yes",]) # 324 out of 1215 = 26.7% 

plot.barchart <- function(df.barchart, cols = c("grey", "blue", "green", "purple", "yellow", "pink"),filename = "barchart_AS.pdf") {
  pdf(filename, width=3, height=4)

  polycol <- trellis.par.get("superpose.polygon")
  # colors will fill from last row upwards
  polycol$col <- cols
  trellis.par.set("superpose.polygon",polycol)

  print(barchart(as.numeric(as.character(fraction))~factor, data = df.barchart, groups=p_n,
                 stack=TRUE,
                 as.table=TRUE,
                 layout=c(1,1),
               #auto.key = list(title = "",rows=3,fill=colors,just="bottom"),
                 #ain="H3R26Cit Peaks",
               #xlab = "HSF1 or HSF2 Peaks",
                 ylab="Fraction with shifted max TSS",
                 cex.axis=1.2,
                 between=list(y=0.5, x=0.5),
                 font.axis=1,
                 par.settings=list(par.xlab.text=list(cex=1.0,font=1),
                   par.ylab.text=list(cex=1.2,font=1),
                   axis.text=list(cex=1,font=1),
                   strip.background=list(col="#ecdaf5"),
                   par.main.text=list(cex=1.2, font=1)),
                                        #aspect = 1,
                 scales=list(x=list(alternating=c(1,1,1,0,0,0),rot=0),
                   y=list(alternating=c(1,1)))))
  
  dev.off()
}

num = c(119,173,57,235)
totals = c(292,292,292,292)
p_n = c("ayes","bno","ayes","bno")
factor = c("Down","Down","Matched","Matched")
barDF = as.data.frame(cbind(num,totals,p_n,factor))
barDF$fraction = as.numeric(barDF$num)/as.numeric(barDF$totals)
barDF
#   num totals  p_n  factor  fraction
# 1 119    293 ayes    Down 0.4061433
# 2 174    293  bno    Down 0.5938567
# 3  10     41 ayes Matched 0.2439024
# 4  31     41  bno Matched 0.7560976

colors = c("orange","grey")
plot.barchart(barDF,cols=colors,filename="barchart_downPromo_TSSshifts_20240326.pdf")

```

## Quantified cTSS and dTSS changes after ZNF143 degradation (Fig. 3F)

### Violin plot
```{r engine='R', eval=F, echo=TRUE}
library(reshape2)

# Add read counts at cTSS positions in the dTAG condition to the giant table
cTSSbed = znf143genesDF[,c("cTSSchr","cTSSstart","cTSSend","gene","cTSSheight","strand")]
bwPlus = load.bigWig(bw.plusDtag)
bwMinus = load.bigWig(bw.minusDtag)
cTSSbed$cTSSdCount = bed6.region.probeQuery.bigWig(bwPlus, bwMinus, cTSSbed, op = "sum", abs.value = TRUE, gap.value = 0)
test = merge(znf143genesDF,cTSSbed[,c("gene","cTSSdCount")],by="gene",all.x=TRUE)
znf143genesDF = test

# Add read counts at dTSS positions in the control samples to the giant table
dTSSbed = znf143genesDF[,c("dTSSchr","dTSSstart","dTSSend","gene","dTSSheight","strand")]
# 84 genes with NA for dTSS coordinates; need to be removed for probeQuery 
dTSSbed = dTSSbed[!is.na(dTSSbed$dTSSchr),]
bwPlus = load.bigWig(bw.plus)
bwMinus = load.bigWig(bw.minus)
dTSSbed$dTSScCount = bed6.region.probeQuery.bigWig(bwPlus, bwMinus, dTSSbed, op = "sum", abs.value = TRUE, gap.value = 0)
test = merge(znf143genesDF,dTSSbed[,c("gene","dTSScCount")],by="gene",all.x=TRUE)
znf143genesDF = test

# Categorize all TSSs
znf143genesDF$cTSSinc = as.numeric(znf143genesDF$cTSSdCount) > as.numeric(znf143genesDF$cTSSheight)
znf143genesDF$dTSSinc = as.numeric(znf143genesDF$dTSSheight) > as.numeric(znf143genesDF$dTSScCount)

downPromoAll = znf143genesDF[znf143genesDF$catRS == "Down" & znf143genesDF$disMOTIFcTSS > -500 & znf143genesDF$disMOTIFcTSS < 0,] 

downPromoShiftYesCTSStall = melt(downPromoAll[downPromoAll$TSSshift == "Yes",c("gene","cTSSheight","cTSSdCount","cTSSinc")], id.vars=c("gene","cTSSinc"), variable.name="dTAGcondition", value.name="TSSheight")

downPromoShiftYesDTSStall = melt(downPromoAll[downPromoAll$TSSshift == "Yes",c("gene","dTSSheight","dTSScCount","dTSSinc")], id.vars=c("gene","dTSSinc"), variable.name="dTAGcondition", value.name="TSSheight")

downPromoShiftYesCTSStall$TSStype = "Control TSS"
downPromoShiftYesDTSStall$TSStype = "dTAG TSS"

names(downPromoShiftYesDTSStall) = c("gene","cTSSinc", "dTAGcondition", "TSSheight","TSStype")
downPromoShiftsOnly= rbind(downPromoShiftYesCTSStall,downPromoShiftYesDTSStall)
# remove NAs (there were no NAs)
downPromoShiftsOnlyClean = na.omit(as.data.frame(downPromoShiftsOnly)) # 119 genes
downPromoShiftsOnlyClean$dTAGcondition = as.character(downPromoShiftsOnlyClean$dTAGcondition)
downPromoShiftsOnlyClean$dTAGcondition[downPromoShiftsOnlyClean$dTAGcondition == "cTSSheight"] = "control height"
downPromoShiftsOnlyClean$dTAGcondition[downPromoShiftsOnlyClean$dTAGcondition == "dTSScCount"] = "control height"
downPromoShiftsOnlyClean$dTAGcondition[downPromoShiftsOnlyClean$dTAGcondition == "dTSSheight"] = "dTAG height"
downPromoShiftsOnlyClean$dTAGcondition[downPromoShiftsOnlyClean$dTAGcondition == "cTSSdCount"] = "dTAG height"

pdf("gg2_bwViolin_downProm_log10cHeights_allShiftedTSSs.pdf", useDingbats = FALSE, width=5, height=4)
ggplot(downPromoShiftsOnlyClean, aes(x = dTAGcondition,y=log(as.numeric(TSSheight),10))) +
    facet_grid(cols = vars(TSStype)) +
    geom_violin(width=0.8) + 
    geom_boxplot(aes(fill = factor(dTAGcondition)), alpha = .2) + 
    geom_line(aes(group = gene, col = cTSSinc)) + 
    scale_color_manual(name="TSS height\nafter dTAGV1",labels= c("Decreasing","Increasing"),values = c("#5b5b5b8C","#EC008C8C")) +
    geom_point(size = 0.8)+
    scale_x_discrete(labels=c("0 min","30 min")) +
    labs(x="dTAGV1 treatment",y=expression(log[10]~"TSS height"),fill="Condition") +
    theme(panel.background = element_rect(fill="transparent"),
        plot.background = element_rect(fill="transparent", color=NA),
        legend.background = element_rect(fill="transparent"),
        legend.box.background = element_rect(fill="transparent"),
        axis.line = element_line(color = "black"))
dev.off()

```


### Barchart 

```{r engine='R', eval=F, echo=TRUE}
# control TSS increased: 4
length(unique(downPromoAllByShift[downPromoAllByShift$TSStype == "Control TSS" & downPromoAllByShift$cTSSinc == TRUE,"gene"]))
# control TSS decreased: 115 (total 119)
length(unique(downPromoAllByShift[downPromoAllByShift$TSStype == "Control TSS" & downPromoAllByShift$cTSSinc == FALSE,"gene"]))

# dTAG TSS increased: 81
length(unique(downPromoAllByShift[downPromoAllByShift$TSStype == "dTAG TSS" & downPromoAllByShift$cTSSinc == TRUE,"gene"]))
# dTAG TSS decreased: 38 (total 119)
length(unique(downPromoAllByShift[downPromoAllByShift$TSStype == "dTAG TSS" & downPromoAllByShift$cTSSinc == FALSE,"gene"]))

# no shift increased: 29
length(unique(downPromoAllByShift[downPromoAllByShift$TSStype == "No shift" & downPromoAllByShift$cTSSinc == TRUE,"gene"]))
# no shift decreased: 145 (total 174)
length(unique(downPromoAllByShift[downPromoAllByShift$TSStype == "No shift" & downPromoAllByShift$cTSSinc == FALSE,"gene"]))

num = c(4,115,81,38,29,145)
totals = c(119,119,119,119,174,174)
p_n = c("aInc","bDec","aInc","bDec","aInc","bDec")
factor = c("Control","Control","dTAG","dTAG","No shift","No shift")
barDF = as.data.frame(cbind(num,totals,p_n,factor))
barDF$fraction = as.numeric(barDF$num)/as.numeric(barDF$totals)
barDF
#   num totals  p_n      factor   fraction
# 1   4    119 aInc Control TSS 0.03361345
# 2 115    119 bDec Control TSS 0.96638655
# 3  81    119 aInc    dTAG TSS 0.68067227
# 4  38    119 bDec    dTAG TSS 0.31932773
# 5  29    174 aInc    No shift 0.16666667
# 6 145    174 bDec    No shift 0.83333333
colors = c("#EC008C8C","#5b5b5b8C")
plot.barchart(barDF,cols=colors,filename="barchart_downPromo_TSSshiftIncreases_20240326.pdf")

# manually change y-axis label to "Fraction of TSSs that Increased +dTAG"
# and add numbers for each category

```

# Heatmaps of promoter-enriched motifs 

## Identify boundaries of promoters with divergent TSSs 

```{r engine='R', eval=F, echo=TRUE}
library(bigWig)
# Identify sense TSSs
# Note the order of the bigWig files--this is necessary for using PE2 files to identify sense-direction TSSs for genes
bw.plus='HEK_CloneZD29_30min_control_minus_PE2_scaled.bigWig'
bw.minus='HEK_CloneZD29_30min_control_plus_PE2_scaled.bigWig'
# densityFilter = TRUE means it will only look for the predominant TSS in each gene.
realPredomBase = TSSinference(gene.exon1, bw.plus, bw.minus, tssWin = 100, top.num.peaks = 20, low.limit.tss.factor = 3, denWin = 100, densityFilter = TRUE)
realPredom = realPredomBase[!(is.na(realPredomBase$height)),]
realPredom = realPredom[!(realPredom$chrom == "chrM"),]

# Make a metaprofile of signal on anti-sense strand relative to sense TSSs
realPredomBed = fiveprime.bed(realPredom, upstreamWindow = 500, downstreamWindow = 100)
yBoth = metaprofile.bigWig(realPredomBed, bwMinus, bw.minus = bwPlus,
                 step = 1, name = "Signal", matrix.op = NULL,
                 profile.op = bootstrapped.confinterval.metaprofile,
                 alpha=0.05, n.samples=1000)

plot(seq(-500,100),yBoth$middle, ylab = "divergent TSS PROseq signal", xlab = "Distance from predominant TSS", type = "l")
polygon(c(seq(-330,0), 0,-330),c(yBoth$middle[170:500],0,0), col="lightblue")
# This plot is named: "divergent_signal_80_percent_AUC_shaded.pdf"

# Redefine search area for anti-sense TSSs based on previous plot
divergBed = realPredom[,1:6]
divWin = 346 # basepairs upstream of sense TSS to anchor search window 
# for plus strand genes, move start to (start - divWin)
# and move end to (end - 57)
divergBed[,2][divergBed$strand == "+"] = divergBed[,2][divergBed$strand == "+"] - divWin
divergBed[,3][divergBed$strand == "+"] = divergBed[,3][divergBed$strand == "+"] - 57
# for minus strand genes, move end to (end + divWin)
# and move start to (start + 57)
divergBed[,3][divergBed$strand == "-"] = divergBed[,3][divergBed$strand == "-"] + divWin
divergBed[,2][divergBed$strand == "-"] = divergBed[,2][divergBed$strand == "-"] + 57

# Identify anti-sense direction TSSs 
# Note: a key change from the previous is the flipping of the order of the bigWig files, as named above
divNoDensTSSbase = TSSinference_wip(divergBed, bw.minus, bw.plus, tssWin = 0, top.num.peaks = 20, low.limit.tss.factor = 3, denWin = 100, densityFilter = FALSE)
divNoDensTSS = divNoDensTSSbase[!(is.na(divNoDensTSSbase$height)),]

divNoDensPredomTSS = do.call(rbind, lapply(split(divNoDensTSS, as.factor(divNoDensTSS$gene)), function(x) {return(x[which.max(x$height),])}))

# Order antisense TSSs in order of decreasing distance from sense TSS
divSenseDiff = as.data.frame(c())
for (i in unique(divNoDensPredomTSS$gene)){
    st = divNoDensPredomTSS[divNoDensPredomTSS$gene == i,]$strand
    chrom = divNoDensPredomTSS[divNoDensPredomTSS$gene == i,]$chrom
    if (st == "+"){
        newStart = divNoDensPredomTSS[divNoDensPredomTSS$gene == i,]$end
        newEnd = realPredom[realPredom$gene == i,]$start
        dist = newEnd - newStart
        newRow = c(chrom, newStart, newEnd, i, "div_sense_diff", st, dist)
        divSenseDiff = rbind(divSenseDiff, newRow)
    } else if (st == "-") {
        newStart = realPredom[realPredom$gene == i,]$end
        newEnd = divNoDensPredomTSS[divNoDensPredomTSS$gene == i,]$start
        dist = newEnd - newStart
        newRow = c(chrom, newStart, newEnd, i, "div_sense_diff", st, dist)
        divSenseDiff = rbind(divSenseDiff, newRow)
    }
}
colnames(divSenseDiff) = c(colnames(divPredomTSS)[1:6],"distance")
divSenseDiff = divSenseDiff[order(divSenseDiff$distance, decreasing = TRUE),]

# Not every gene will have a corresponding anti-sense TSS.
# Keep only genes that have both types of predominant TSS:
realPredomDiffOrder = realPredom[realPredom$gene %in% divSenseDiff$gene,]
# Reorder realPredom by divSenseDiff order
realPredomDiffOrder = realPredomDiffOrder[order(match(realPredomDiffOrder$gene, divSenseDiff$gene)),]
# Check if order is correct
identical(realPredomDiffOrder$gene, divSenseDiff$gene)
# [1] TRUE

# Add distance column
realPredomDiffOrder$TSSdistance = divSenseDiff$distance

# write to file
write.table(realPredomDiffOrder, file = "predomTSS_dec_divTSSdistance_order.bed", quote = FALSE, sep ='\t', row.names = FALSE, col.names = FALSE)
```

Create heatmap of anti-sense and sense TSSs, ordered by decreasing distance between the two (Fig 6A):

```{r engine='R', eval=F, echo=TRUE}
# This script is available in the "PRO_analysis" folder in the repository containing this vignette
source("/Users/jinhongdong/Desktop/TSSinference/heatmaps_mjg_functions.R")

y = read.table('predomTSS_dec_divTSSdistance_order.bed')
#this helps make a window that is not off by one intended base
y[y[,6] == "+",][,3] = y[y[,6] == "+",][,3] -1
y[y[,6] != "+",][,2] = y[y[,6] != "+",][,2] +1

compObject = create.composites.heatmaps("/Users/jinhongdong/Desktop/TSSinference/ZNF143dTag_2023/oldwigs/", y, region = 700, step = 1, file.prefix = "HEK_CloneZD29*scaled")

draw.heatmap.both.pro.overlap(compObject[[2]], file = 'uaTSS_sTSS_decreasing_dist_heatmap.pdf', upstream = -700, downstream = 700, convert.zeros =FALSE, sub.set = 8000, arrangement = 'asis', order.buffer = 1, avg.rows = 20,
                              width.vp = 2, height.vp = 4, colors.ramp = c("#ffffff00","#FF0000FF", "#590000FF", "#510000FF", "#2F0000FF", "#2d0101FF","#2E0000FF"),
                              colors.ramp.2 = c("#ffffff00","#0000FF80", "#00105980", "#00115180", "#00072F80", "#00072E80", "#01072d80"))
  
```


## FIMO of motifs (Fig. 5B, 6A, S8)

This loop runs through all the mentioned motifs used in the paper and looks for matches in the entire hg38 reference genome. Motifs queried (JASPAR database version):

- MA0506.2 Nrf1
- MA0516.3 SP2
- MA0750.2 ZBTB7A (ETS)
- MA1145.1 FOSL2::JUND (bZIP)
- MA1651.1 YY1

```{r engine='bash', eval=F, echo=TRUE}
genome="/Users/jinhongdong/fileRef/human38/hg38.fa"
for i in *meme # motifs mentioned above
do
  mot=$(echo $i | cut -f 1,2 -d '.')
  echo $mot
  echo "Start: $(date)"
  fimo --text --max-stored-scores 10000000 -oc ${mot}_out --motif $mot $i $genome > ${mot}_fimo_out.txt
  echo "End: $(date)"
done 2>&1 | tee fimo_log.txt

```

Afterward, to create the heatmaps, convert the FIMO outputs into bigWigs:

```{r engine='bash', eval=F, echo=TRUE}
hg38chromSize="/Users/jinhongdong/fileRef/human38/hg38.chrom.sizes"

for i in *fimo_out.txt
do
  MOTIF=$(echo $i | cut -f 1 -d "_")
  # Convert FIMO output into BED format 
  # The 5th column of these BEDs can just be the pvalue or score fimo/MAST gives you
  awk '{OFS="\t";} { if($6=="+") print $3, $4, $5, $7}' ${MOTIF}_fimo_out.txt | sort -k 1,1 -k2,2n | mergeBed -c 4 -o mean -d -1 > ${MOTIF}_fimo_plus.bed
  awk '{OFS="\t";} { if($6=="-") print $3, $4, $5, $7}' ${MOTIF}_fimo_out.txt | sort -k 1,1 -k2,2n | mergeBed -c 4 -o max -d -1 > ${MOTIF}_fimo_minus.bed
  # The filenames of the output bigWigs have `_PE2_scaled` 
  # for naming consistency in the R functions
  wigToBigWig ${MOTIF}_fimo_plus.bed $hg38chromSize ${MOTIF}_fimo_plus_PE2_scaled.bigWig 
  wigToBigWig ${MOTIF}_fimo_minus.bed $hg38chromSize ${MOTIF}_fimo_minus_PE2_scaled.bigWig 
done

```

To make the heatmaps and composite plots, make a template script to be populated with the specific motif name:

"fimo_plots_template.R":

```{r engine='R', eval=F, echo=TRUE}
#!/usr/local/bin/Rscript

setwd("/Users/jinhongdong/Desktop/TSSinference/fimo")

library(bigWig)
library(lattice)

# This script is available in the "PRO_analysis" folder in the repository containing this vignette
source("/Users/jinhongdong/Desktop/TSSinference/heatmaps_mjg_functions.R")

y = read.table('predomTSS_dec_divTSSdistance_order.bed')

z = y[y[,6] == "+",]
z[z[,6] == "+",][,3] = z[z[,6] == "+",][,3] -1

#this helps make a window that is not off by one intended base
y[y[,6] == "+",][,3] = y[y[,6] == "+",][,3] -1
y[y[,6] != "+",][,2] = y[y[,6] != "+",][,2] +1

plotHM = create.composites.heatmaps('/Users/jinhongdong/Desktop/TSSinference/fimo', y, region = 700, step = 1, file.prefix = 'XXX')

# PDF of heatmap in the anchored region
draw.heatmap.both.pro.overlap(plotHM[[2]], file = 'XXX_heatmap_fimo.pdf', upstream = -700, downstream = 700, convert.zeros =FALSE, sub.set = 8000, arrangement = 'asis', order.buffer = 1, avg.rows = 1,
                              width.vp = 2, height.vp = 4, colors.ramp = c("#ffffff00","#FF0000FF", "#590000FF", "#510000FF", "#2F0000FF", "#2d0101FF","#2E0000FF"),
                              colors.ramp.2 = c("#ffffff00","#0000FF80", "#00105980", "#00115180", "#00072F80", "#00072E80", "#01072d80"))

# PDF of composite signal peaks according to anchor region. 
composites.func.panels.pro.2(plotHM[[1]], num = 700, fact = "XXX", col.lines = c('blue', 'red'))
```

This loop creates individual R scripts for each motif: 

```{r engine='bash', eval=F, echo=TRUE}
file="fimo_plots_template.R"

for i in *fimo_out.txt
do
  MOTIF=$(echo $i | cut -f 1 -d "_")
  echo $MOTIF
  sed -e "s/XXX/${MOTIF}/g" "$file" > ${MOTIF}_fimo_plots.R
done

for i in *plots.R
do
  Rscript $i
done

```



